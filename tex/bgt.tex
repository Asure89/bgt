\documentclass{bioinfo}
\copyrightyear{2015}
\pubyear{2015}

\usepackage{amsmath}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{natbib}

\bibliographystyle{apalike}


\begin{document}
\firstpage{1}

\title[Large-scale Genotype Query]{BGT: efficient and flexible genotype query across many samples}

\author[Li]{Heng Li}

\address{Broad Institute, 7 Cambridge Center, Cambridge, MA 02142, USA}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}
\editor{Associate Editor: XXXXXXX}
\maketitle

\begin{abstract}
\section{Summary:} BGT is a compact format, a fast command line tool and a
simple web application for efficiently and conveniently querying whole-genome
genotypes and frequencies across tens to hundreds of thousands of samples.
On real data, it compresses the genotypes of 32,488 samples across 39.2
million sites down to a 7.4GB database and processes a couple of hundred
million genotypes per CPU second.

\section{Availability and implementation:} https://github.com/lh3/bgt

\section{Contact:} hengli@broadinstitute.org
\end{abstract}

\section{Introduction}

VCF/BCF~\citep{Danecek:2011qy} is the primary format for storing and analyzing
genotypes of multiple samples.  It however has a few issues. Firstly, as a
streaming format, VCF compresses all types of information together. Retrieving
site annotations or the genotypes of a few samples usually requires to decoding
the genotypes of all samples, which is unnecessarily expensive. Secondly, VCF
does not take advantage of linkage disequillibrium (LD), while using this
information can dramatically improve compression ratio~\citep{Durbin:2014yq}.
Thirdly, a VCF record is not clearly defined. Each record may consist of
multiple alleles with each allele composed of multiple SNPs and INDELs. This
ambiguity complicates annotations, query of alleles and integration of multiple
data sets. At last, most existing VCF-based tool chains do not support
expressive data query.  We frequently need to write scripts for advanced
queries, which costs both development and processing time. BGT is designed to
overcome or alleviate these issues.

\begin{methods}
\section{Methods}

\subsection{Design}

\subsubsection{Data model}

BGT keeps diploid genotypes as a 2-bit integer matrix $(H_{ki})$ with row
indexed by a pair of overlapping reference/non-reference alleles and column by
a sample haplotype (thus for $m'$ samples, the matrix has $2m'$ columns).
$H_{ki}$ takes value 0 if the $i$-th haplotype has the reference allele in the
allele pair at row $k$, takes 1 if the haplotype has the non-reference allele,
2 if unknown and 3 if the haplotype has a different non-reference allele. BGT
arbitrarily phases unphased genotypes and always breaks complex variants in VCF
down to the smallest possible variants. It keeps the allele pairs (i.e. rows)
in a site-only BCF, disallowing multiple alleles per VCF line, and stores the
integer matrix as two positional BWTs (PBWTs), one for the lower bit and the
other for the higher bit.

\subsubsection{PBWT overview}

PBWT is a generic way to encode binary matrices.
Let $(A_k)_{0\le k<n}=(A_0,\ldots,A_{n-1})$ be a list of $m$-long binary
strings. $(A_k)_k$ can be regarded as an $n\times m$ binary matrix with
$A_k[i]$ represencting the cell at row $k$ and column $i$.  For simplicity,
introduce a sentinel row $A_{-1}=\$_0\$_1\cdots\$_{m-1}$ with a lexicographical
order $\$_0<\cdots<\$_{m-1}$.

Define binary string:
\[
P_{ki}=A_k[i]A_{k-1}[i]\ldots A_0[i]A_{-1}[i]
\]
to be the reverse of the column prefix ending at $(k,i)$ and define $S_k(i)$ to
be the column index of the $i$-th smallest prefix among set $\{P_{kj}\}_j$.
$S_k(i)$ is a bijection on $\{0,\ldots,m-1\}$ and thus invertible. In a
special case, $S_{-1}(i)=i$ because $P_{-1,i}=A_{-1}[i]=\$_i$.

The PBWT of $(A_k)_{0\le k<n}$ is $(B_k)_{0\le k<n}$, which is
calculated by
\begin{equation*}\label{eq:B}
B_k[i]=A_k[S_{k-1}(i)]
\end{equation*}
An important use of $(B_k)_k$ is to compute $S_k$. Define
\begin{equation*}\label{eq:phi}
\phi_k(i)=C_k(B_k[i])+{\rm rank}_k(B_k[i],i)
\end{equation*}
where $C_k(b)$ gives the number of symbols in $B_k$ that are lexicographically
smaller than $b$ and ${\rm rank}_k(b,i)$ the number of $b$ symbols in $B_k$
before position $i$. The $i$-th smallest column in row $k-1$ is ranked
$\phi_k(i)$ in row $k$. Thus
\begin{equation*}\label{eq:trans}
S_k(\phi_k(i))=S_{k-1}(i)
\end{equation*}
Given $A_k$ and $S_{k-1}$, we can compute $S_k$ and $B_k$ in the order of
$B_k\to\phi_k\to S_k$, starting from $k=0$. Conversely, given $B_k$ and
$S_{k-1}$, computing $\phi_k\to S_k\to A_k$ derives $A_k$ from $B_k$.

When there are strong correlations between adjacent rows, which is true for
haplotype data due to linkage disequillibrium, $0$s and $1$s tend to form long
runs in $B_k$. This usually makes $B_k$ much more compressible than $A_k$ under
run-length encoding. For our test data set, 32 thousand samples can be
compressed to less than 200 bytes in average.

\subsection{Query with BGT}

\subsubsection{Flat Metadata Format (FMF)}

BGT introduces a new but simple text format, FMF, to manage meta data. FMF is
TAB-delimited with the first column showing the row name and following columns
giving typed key-value pairs. An example looks like:
\begin{center}
\begin{verbatim}
  sample1   gender:Z:M   height:f:1.73   foo:i:10
  sample2   gender:Z:F   height:f:1.64   bar:i:20
\end{verbatim}
\end{center}
where rows can be retrieved by an arbitrary expression such as
``height$>$1.65''. It has a similar data model to wide-column databases. BGT
uses FMF to keep and query sample phenotypes and variant annotations.

\subsubsection{Query genotypes}

The BGT query system is inspired by SQL.  Notably, BGT can select variants and
samples with arbitrary conditions on meta data (analogy: the {\sf WHERE} clause
in SQL). It has a few built-in aggregate variables such as the allele count of
selected samples (analogy: the aggregate functions) and can filter output with
these variables (analogy: the {\sf HAVING} clause). BGT outputs VCF/BCF by
default, but it may optionally output user requested fields only (analogy:
fields in the {\sf SELECT} statement). BGT also allows to create multiple
sample groups with allele count calculated for each group and to set conditions
on them (see Results), which is inspired by SQL's joining multiple instances of
the same table in the {\sf FROM} clause.

On the other hand, the query syntax of BGT is very different from SQL. It tends
to be simpler as BGT only has a few `tables' with fixed relationship. BGT can
also count haplotypes across a given set of variants, which is not easy to
implement with a pure SQL backend.

\subsection{BGT server}

BGT comes with a standalone web server frontend implemented in the Go
programming language. The server has a similar interface to the command line
tool, but with additional consideration of sample anonymity. With BGT,
each sample has an attribute minimal group size or MGS. On query, the server
refuses to create a sample group if the size of this group is smaller than the
MGS of one sample in this group. In particular, if a sample has MGS larger than
one, users cannot access its sample name and individual genotypes, but can
retrieve allele counts computed together with other samples.

\end{methods}

\section{Results}

We generated the BGT database for the first release of Haplotype Reference
Consortium (HRC; http://bit.ly/HRC-org). The input is a BCF containing 32,488 samples across 39.2
million sites on autosomes. The BGT file size is 7.4GB, 11\% of the
genotype-only BCF. Decoding the genotypes of all
samples across 142k sites in a 10Mbp region takes 11 CPU seconds, which amounts
to decoding 420 million genotypes per second. This speed is even faster than
computing allele counts and outputting VCF.

We use the following command line to demonstrate the query syntax of BGT:
\begin{center}\footnotesize
\begin{verbatim}
  bgt view -G -d var.fmf.gz -a'gene=="BRCA1"' \
    -s 'source=="IBD"' -s 'source=="1000G"' \
    -f 'AC1/AN1>=0.001&&AC2/AN2>=0.001' \
   HRC-r1.bgt
\end{verbatim}
\end{center}
It finds chr11 coding variants annotated in `var.fmf.gz' that have $\ge$0.1\%
frequency in the IBD data set (http://www.ibdresearch.co.uk) but absent from
1000 Genomes~\citep{1000-Genomes-Project-Consortium:2012aa}. In this command line, {\tt -G} disables the output of genotypes.
Option {\tt -a} selects variants with the `gene' attribute equal to `BRCA1'
according to the variant database specified with {\tt -d}. This condition
is indepenent of sample genotypes. Each option {\tt -s} selects a group of
samples, again independent of sample genotypes.  For the \char35-th sample
group/{\tt -s}, BGT counts the total number of called alleles and the number of
non-reference alleles and writes them to the {\tt AN\char35} and {\tt
AC\char35} aggregate variables, respectively. Option {\tt -f} then use these
aggregate variables to filter output.

This command line takes 12 CPU seconds with most of time spent on reading
through the variant annotation file to find matching alleles. The BGT server
reads the entire file into memory to alleviate the overhead, but a better
solution would be to set up a proper database for variant annotations.

\section{Discussions}

Given a multi-sample VCF, most BGT functionalities can be achieved with small
scripts. However, as a command line tool, BGT is still an advance in several
ways. Firstly, it saves development time. Extracting information from multiple
files can be done with a command line instead of a script.  Secondly,
BGT saves processing time. With high-performance C code at the core, BGT is
much faster than processing VCF in a scripting language such as Perl or Python.
For example, deriving allele counts in a 10Mbp region for the HRC data takes 30
seconds with BGT, but doing the same with a Perl script takes 40 minutes, a
80-fold difference. Thirdly, the design of one non-reference allele per record
and the separation of variant annotation from genotype data helps more scalable
data processing. These design choices make BGT merge is much simpler and faster
than generic VCF merge. This enables efficient query across multiple BGT
databases which is not practical with VCF.

The BGT server tries to solve a bigger problem: data sharing. A key feature of
the server is to make the user-requested summary of genotypes available while
keeping samples unidentifiable~\citep{Stade:2014ty}. Instead of always
delivering full data in VCF, projects could have a new option to serve data
publicly with BGT, letting users select the summary statistics of interest
without breaching privacy.

% summary data is smaller, but genotypes in PBWT is not large, either.

We acknowledge that our MGS-based data sharing policy might have oversimplified
real scenarios, but we believe this direction, with proper improvements and
more importantly the approval of ethical review boards, will be more open,
convenient, efficient and secure than our current
share-everything-with-permission model.

\section*{Acknowledgement}
I am grateful to HRC for granting the permission to use the data for evaluating
the performance of BGT and thank the Global Alliance for the helpful
suggestions.
\paragraph{Funding\textcolon} NHGRI U54HG003037; NIH GM100233

\bibliography{bgt}
\end{document}
